# Local LLM and AI Control Dependencies
# Install with: pip install -r requirements-ai.txt

# LLM Backends
ollama>=0.1.0                    # Ollama Python client
llama-cpp-python>=0.2.0          # llama.cpp bindings (optional)
# vllm>=0.2.0                    # vLLM backend (optional, GPU required)

# HTTP and async support
httpx>=0.25.0                    # Async HTTP client
aiohttp>=3.9.0                   # Async HTTP

# CLI interface
click>=8.1.0                     # CLI framework

# Embeddings for RAG
sentence-transformers>=2.2.0     # Sentence embeddings

# Core ML (already in requirements.txt)
# torch>=2.1.0
# transformers>=4.36.0

# Security and validation
# cryptography>=42.0.0           # Already in requirements.txt

# Optional: Better async runtime
# uvloop>=0.19.0                 # Faster event loop (Unix only)
